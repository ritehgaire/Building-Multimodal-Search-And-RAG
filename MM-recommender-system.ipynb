{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "824e0c5e-758a-448f-b125-1068d9b52a20",
   "metadata": {},
   "source": [
    "Cell 1: Setup Environment Variables and API Keys\n",
    "The aim is to load environment variables and configure the API keys for multimodal embeddings and text embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c86d194-e02a-4ad3-a142-72314e2d9e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables and API keys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # Read local .env file\n",
    "\n",
    "# Get API keys from environment variables\n",
    "MM_EMBEDDING_API_KEY = os.getenv(\"EMBEDDING_API_KEY\")\n",
    "TEXT_EMBEDDING_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "OPENAI_BASEURL = os.getenv(\"OPENAI_BASE_URL\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee235be-66de-4c6c-bc2c-0fa902d24df3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3828f7bb-8e6a-4b7e-81c9-06a2c7b62ce9",
   "metadata": {},
   "source": [
    "Cell 2: Connect to Weaviate\n",
    "Establish a connection to the Weaviate instance and configure it to use multi-vector spaces (text and image vectors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10068656-9391-4b0f-9923-587200ac410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "# Connect to Weaviate and set the vectorizer modules\n",
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"1.24.4\",\n",
    "    environment_variables={\n",
    "        \"ENABLE_MODULES\": \"multi2vec-palm,text2vec-openai\"\n",
    "    },\n",
    "    headers={\n",
    "        \"X-PALM-Api-Key\": MM_EMBEDDING_API_KEY,\n",
    "        \"X-OpenAI-Api-Key\": TEXT_EMBEDDING_API_KEY,\n",
    "        \"X-OpenAI-BaseURL\": OPENAI_BASEURL\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check if the client is ready\n",
    "client.is_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09891121-4d07-493e-b991-44ba4f9fc099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e68822de-df3e-41e3-8203-341fcd3b8b72",
   "metadata": {},
   "source": [
    "Cell 3: Create Multivector Collection\n",
    "Create a Movies collection in Weaviate with properties for text and images, and configure the vector spaces for text and image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49204fee-bf99-4535-bad8-0ce42a1321b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.config import Configure, DataType, Property\n",
    "\n",
    "# Create the 'Movies' collection with text and image properties\n",
    "client.collections.create(\n",
    "    name=\"Movies\",\n",
    "    properties=[\n",
    "        Property(name=\"title\", data_type=DataType.TEXT),\n",
    "        Property(name=\"overview\", data_type=DataType.TEXT),\n",
    "        Property(name=\"vote_average\", data_type=DataType.NUMBER),\n",
    "        Property(name=\"release_year\", data_type=DataType.INT),\n",
    "        Property(name=\"tmdb_id\", data_type=DataType.INT),\n",
    "        Property(name=\"poster\", data_type=DataType.BLOB),\n",
    "        Property(name=\"poster_path\", data_type=DataType.TEXT),\n",
    "    ],\n",
    "    \n",
    "    # Configure the vector spaces for text and images\n",
    "    vectorizer_config=[\n",
    "        Configure.NamedVectors.text2vec_openai(\n",
    "            name=\"txt_vector\",\n",
    "            source_properties=[\"title\", \"overview\"],\n",
    "        ),\n",
    "        Configure.NamedVectors.multi2vec_palm(\n",
    "            name=\"poster_vector\",\n",
    "            image_fields=[\"poster\"],\n",
    "            project_id=\"semi-random-dev\",\n",
    "            location=\"us-central1\",\n",
    "            model_id=\"multimodalembedding@001\",\n",
    "            dimensions=1408,\n",
    "        ),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9a392-30a6-49f4-ad53-b60968603c57",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d88e471-607a-44bd-9d3a-c0125780321b",
   "metadata": {},
   "source": [
    "Cell 4: Load Movie Data\n",
    "Load movie data from a JSON file to insert into the Weaviate collection.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675db66-4572-4d4f-bd88-d1f62940e00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load movie data from JSON file\n",
    "df = pd.read_json(\"movies_data.json\")\n",
    "df.head()  # Display the first few rows of the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ab221e-dd19-4e63-a244-aa5d48c9df4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "73f155b1-0072-44ab-abca-45a88d98d385",
   "metadata": {},
   "source": [
    "Cell 5: Helper Function for Image Processing\n",
    "Define a helper function to convert image files to base64 encoding for inserting image data into Weaviate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499f9fc2-1c39-4190-98bb-1337def1fade",
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "\n",
    "# Convert an image file to base64 encoding\n",
    "def toBase64(path):\n",
    "    with open(path, 'rb') as file:\n",
    "        return base64.b64encode(file.read()).decode('utf-8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1ca7dc-08ab-47fb-95ea-2b19acb37c2a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "7ab30710-eac6-4cea-ae40-595432f378a1",
   "metadata": {},
   "source": [
    "Cell 6: Insert Movie Data into Weaviate\n",
    "Insert movies from the dataframe into the Weaviate collection, using both text and image data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3002244-ae1d-4acc-bc27-ccb9351416dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.util import generate_uuid5\n",
    "\n",
    "# Get the 'Movies' collection from Weaviate\n",
    "movies = client.collections.get(\"Movies\")\n",
    "\n",
    "# Batch process to insert movie data\n",
    "with movies.batch.rate_limit(20) as batch:\n",
    "    for index, movie in df.iterrows():\n",
    "        \n",
    "        # Skip the movie if it already exists\n",
    "        if movies.data.exists(generate_uuid5(movie.id)):\n",
    "            print(f'{index}: Skipping insert. The movie \"{movie.title}\" is already in the database.')\n",
    "            continue\n",
    "        \n",
    "        print(f'{index}: Adding \"{movie.title}\"')\n",
    "        \n",
    "        # Path to the movie poster image file\n",
    "        poster_path = f\"./posters/{movie.id}_poster.jpg\"\n",
    "        posterb64 = toBase64(poster_path)  # Convert poster to base64\n",
    "\n",
    "        # Build the movie object with text and image data\n",
    "        movie_obj = {\n",
    "            \"title\": movie.title,\n",
    "            \"overview\": movie.overview,\n",
    "            \"vote_average\": movie.vote_average,\n",
    "            \"tmdb_id\": movie.id,\n",
    "            \"poster_path\": poster_path,\n",
    "            \"poster\": posterb64\n",
    "        }\n",
    "\n",
    "        # Add object to batch queue\n",
    "        batch.add_object(\n",
    "            properties=movie_obj,\n",
    "            uuid=generate_uuid5(movie.id),\n",
    "        )\n",
    "\n",
    "# Check for any failed inserts\n",
    "if len(movies.batch.failed_objects) > 0:\n",
    "    print(f\"Failed to import {len(movies.batch.failed_objects)} objects\")\n",
    "else:\n",
    "    print(\"Import complete with no errors\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ffc77b-8442-46e4-8aca-7074b7ff0ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ece0d352-add1-4926-b372-980eda71f031",
   "metadata": {},
   "source": [
    "Cell 7: Text Search in Text Vector Space\n",
    "Perform a semantic text search on the movie titles and overviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90917dd0-2ada-49b6-b1a4-3df76c45d217",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "\n",
    "# Perform a text search in the text vector space\n",
    "response = movies.query.near_text(\n",
    "    query=\"Movie about lovable cute pets\",\n",
    "    target_vector=\"txt_vector\",\n",
    "    limit=3,\n",
    ")\n",
    "\n",
    "# Display the search results\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"title\"])\n",
    "    print(item.properties[\"overview\"])\n",
    "    display(Image(item.properties[\"poster_path\"], width=200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981402a8-65e1-4dcf-9604-9e91286044bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "40e9a0a1-edba-4857-9571-ab0eee3fc8a0",
   "metadata": {},
   "source": [
    "Cell 8: Text Search in Poster Vector Space\n",
    "Perform a semantic search using text queries in the image (poster) vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6116f6b-2547-4097-aba6-b65eaa56fd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a text query but search in the poster vector space\n",
    "response = movies.query.near_text(\n",
    "    query=\"Movie about lovable cute pets\",\n",
    "    target_vector=\"poster_vector\",\n",
    "    limit=3,\n",
    ")\n",
    "\n",
    "# Display the search results\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"title\"])\n",
    "    print(item.properties[\"overview\"])\n",
    "    display(Image(item.properties[\"poster_path\"], width=200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8b633b-f7f5-435b-982e-cf9b9bbae30c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad36f875-9246-4c61-892b-4dbc1674f815",
   "metadata": {},
   "source": [
    "Cell 9: Image Search in Poster Vector Space\n",
    "Use an image as a query to search in the poster vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6fa912-5113-44fc-aba9-e52bdb569b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the input image for the query\n",
    "Image(\"test/spooky.jpg\", width=300)\n",
    "\n",
    "# Perform an image-based search in the poster vector space\n",
    "response = movies.query.near_image(\n",
    "    near_image=toBase64(\"test/spooky.jpg\"),\n",
    "    target_vector=\"poster_vector\",\n",
    "    limit=3,\n",
    ")\n",
    "\n",
    "# Display the search results\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"title\"])\n",
    "    display(Image(item.properties[\"poster_path\"], width=200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be25150-07c4-44f0-9cc9-a016420738c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aa5445d6-62a9-4bda-b753-e2b27009d68f",
   "metadata": {},
   "source": [
    "Cell 10: Another Image Search Example\n",
    "Perform another image-based search using a different image as the query.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72e71b0-bcd4-437a-ade5-0435d84b78d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the input image for the query\n",
    "Image(\"test/superheroes.png\", width=300)\n",
    "\n",
    "# Perform an image-based search in the poster vector space\n",
    "response = movies.query.near_image(\n",
    "    near_image=toBase64(\"test/superheroes.png\"),\n",
    "    target_vector=\"poster_vector\",\n",
    "    limit=3,\n",
    ")\n",
    "\n",
    "# Display the search results\n",
    "for item in response.objects:\n",
    "    print(item.properties[\"title\"])\n",
    "    display(Image(item.properties[\"poster_path\"], width=200))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb5c8a2-b16d-480a-8b2b-e954d463a2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "83124859-399e-4156-a882-669bc9667d28",
   "metadata": {},
   "source": [
    "Cell 11: Close the Weaviate Client\n",
    "Ensure the Weaviate client is closed to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "077e6a69-a3c1-4901-a5b9-972711ad105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Weaviate client\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0509f92a-c67d-45b7-8a92-9c252aaa6384",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e5fd89db-fc9a-49b2-b643-fde27700b69e",
   "metadata": {},
   "source": [
    "Description of the Code:\n",
    "This notebook demonstrates the creation of a Multimodal Recommender System using Weaviate. The system uses both text embeddings and image embeddings to perform semantic searches. The process includes:\n",
    "\n",
    "Environment Setup: Load necessary API keys and configure access to OpenAI and Weaviate services.\n",
    "Collection Creation: A Weaviate collection (Movies) is created, with properties for movie titles, overviews, ratings, and posters. The collection is configured with two vector spaces: one for text (titles and overviews) and one for images (posters).\n",
    "Data Insertion: Movie data, including text and poster images, are inserted into the collection in batch mode.\n",
    "Multimodal Search: The system performs text-based searches in both the text and image vector spaces, as well as image-based searches using movie posters as the query.\n",
    "Closing Resources: After the search tasks are completed, the Weaviate client is closed to free up resources.\n",
    "This system allows users to search for movies using both text queries and image queries, demonstrating a multimodal recommender approach.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
