{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a33f2c8d-6dd8-46b5-920e-cc9f42eb8b92",
   "metadata": {},
   "source": [
    "Cell 1: Setup Environment Variables and API Key\n",
    "The goal is to load the necessary API keys and environment variables required for embedding and generative AI services.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345eaa6b-ef9a-49c7-afa4-5ac1452d011a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables and API keys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # Load local .env file\n",
    "EMBEDDING_API_KEY = os.getenv(\"EMBEDDING_API_KEY\")\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fe0869a-329e-403e-8ab4-9b9353fdcc2d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6411a244-b1a6-414f-976a-c8f402dea802",
   "metadata": {},
   "source": [
    "Cell 2: Connect to Weaviate\n",
    "Establish a connection with the Weaviate instance and verify that the connection is ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2cd8768-09f0-4997-a0c8-3d42f2b83b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import weaviate\n",
    "\n",
    "# Connect to Weaviate and set environment variables\n",
    "client = weaviate.connect_to_embedded(\n",
    "    version=\"1.24.4\",\n",
    "    environment_variables={\n",
    "        \"ENABLE_MODULES\": \"backup-filesystem,multi2vec-palm\",\n",
    "        \"BACKUP_FILESYSTEM_PATH\": \"/home/jovyan/work/L4/backups\",\n",
    "    },\n",
    "    headers={\n",
    "        \"X-PALM-Api-Key\": EMBEDDING_API_KEY,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Check if the client is ready\n",
    "client.is_ready()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e43ff452-c0d9-4249-b063-dc6f1d58af2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b18a644-62ea-4440-b2b6-a9a1e0e5d013",
   "metadata": {},
   "source": [
    "Cell 3: Restore Prevectorized Data\n",
    "Restore a backup collection of prevectorized resources from the Weaviate instance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f335f6b6-6fc6-4303-9b71-be7fc6eca604",
   "metadata": {},
   "source": [
    "# Restore a collection from a backup\n",
    "client.backup.restore(\n",
    "    backup_id=\"resources-img-and-vid\",\n",
    "    include_collections=\"Resources\",\n",
    "    backend=\"filesystem\"\n",
    ")\n",
    "\n",
    "# Add a delay to ensure the collection is fully restored before proceeding\n",
    "import time\n",
    "time.sleep(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "885c9d16-8186-42fb-ad5f-55b0d091d995",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "297f3a60-06fd-4ef0-a95b-6a9be03b475d",
   "metadata": {},
   "source": [
    "Cell 4: Preview Data Count\n",
    "Retrieve the count of different media types (images, videos, etc.) in the collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe6788d-20df-4868-b26b-9e71361ba010",
   "metadata": {},
   "outputs": [],
   "source": [
    "from weaviate.classes.aggregate import GroupByAggregate\n",
    "\n",
    "# Get the 'Resources' collection\n",
    "resources = client.collections.get(\"Resources\")\n",
    "\n",
    "# Aggregate and count the number of items in each mediaType\n",
    "response = resources.aggregate.over_all(\n",
    "    group_by=GroupByAggregate(prop=\"mediaType\")\n",
    ")\n",
    "\n",
    "# Print the counts of each media type\n",
    "for group in response.groups:\n",
    "    print(f\"{group.grouped_by.value} count: {group.total_count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16a53a46-5474-40b0-8ec2-e85adf9e908d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e53f133-d659-448b-99cf-c3d80bdda136",
   "metadata": {},
   "source": [
    "Cell 5: Retrieve Image from Query\n",
    "Define a function that retrieves an image from the Weaviate collection based on a text query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c034650c-0459-4ab3-be7c-1407e11855cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from weaviate.classes.query import Filter\n",
    "\n",
    "# Function to retrieve an image based on a query\n",
    "def retrieve_image(query):\n",
    "    resources = client.collections.get(\"Resources\")\n",
    "    response = resources.query.near_text(\n",
    "        query=query,\n",
    "        filters=Filter.by_property(\"mediaType\").equal(\"image\"),  # Only return image objects\n",
    "        return_properties=[\"path\"],\n",
    "        limit=1,\n",
    "    )\n",
    "    result = response.objects[0].properties\n",
    "    return result[\"path\"]  # Return the path to the image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640c035c-ad9d-4e62-adc4-3c2e0bca5789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "772e5c07-f688-4500-b6a3-1fb36d671501",
   "metadata": {},
   "source": [
    "Cell 6: Run Image Retrieval\n",
    "Run the retrieve_image function with a specific query and display the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aba715a-a97f-41c1-a0ec-29962f0cd3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve an image based on a query\n",
    "img_path = retrieve_image(\"fishing with my buddies\")\n",
    "\n",
    "# Display the retrieved image\n",
    "display(Image(img_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0515325-b103-4d80-9283-3c1323a5f26f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2547965f-dad6-4db5-8543-74bec1351c19",
   "metadata": {},
   "source": [
    "Cell 7: Set Up Google Generative AI\n",
    "Configure the Google Generative AI client with the API key for the Gemini Vision model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a92462-2380-46d9-b410-585e0568737a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.generativeai as genai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "# Set up the Google Generative AI library with the Vision model API key\n",
    "genai.configure(\n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    transport=\"rest\",\n",
    "    client_options=ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25bf5990-37b7-4ef0-a5c8-229346931425",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b13d0571-c0da-44a3-af17-06c62626378f",
   "metadata": {},
   "source": [
    "Cell 8: Helper Functions\n",
    "Create helper functions to format text as Markdown and call the Large Multimodal Model (LMM) to generate content based on an image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8520a9-1790-40d4-a442-8c51db47a7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import PIL.Image\n",
    "from IPython.display import Markdown, Image\n",
    "\n",
    "# Convert text to Markdown for better display in notebooks\n",
    "def to_markdown(text):\n",
    "    text = text.replace(\"â€¢\", \"  *\")\n",
    "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
    "\n",
    "# Function to call the LMM (Large Multimodal Model) for generating content from an image\n",
    "def call_LMM(image_path: str, prompt: str) -> str:\n",
    "    img = PIL.Image.open(image_path)  # Load the image\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")  # Load the generative model\n",
    "    response = model.generate_content([prompt, img], stream=True)  # Send the image and prompt\n",
    "    response.resolve()  # Get the model's response\n",
    "    return to_markdown(response.text)  # Format and return the response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a590e74f-db1e-4378-b5ee-46cd9612688b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e27d2c3-cde2-41f3-b79a-4fd112c5d574",
   "metadata": {},
   "source": [
    "Cell 9: Generate Image Description\n",
    "Call the LMM to generate a detailed description of the retrieved image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e07daf-ba2b-4fb4-9d13-614dc4ea6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the LMM to generate a description for the retrieved image\n",
    "call_LMM(img_path, \"Please describe this image in detail.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1184e474-ab57-4f97-b89f-f18f26d94a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1e6d7725-a329-4673-8c15-e0feecc65976",
   "metadata": {},
   "source": [
    "Cell 10: Combine Multimodal RAG Workflow\n",
    "Define a function that integrates both retrieval and generative capabilities in a single multimodal RAG process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c62964-cdcc-4749-b702-21c375f90050",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mm_rag(query):\n",
    "    # Step 1: Retrieve an image using Weaviate\n",
    "    SOURCE_IMAGE = retrieve_image(query)\n",
    "    display(Image(SOURCE_IMAGE))  # Display the retrieved image\n",
    "    \n",
    "    # Step 2: Generate a description using the LMM\n",
    "    description = call_LMM(SOURCE_IMAGE, \"Please describe this image in detail.\")\n",
    "    return description\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27737afe-d8ef-41c6-8d34-79fe41b2bc23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2fbabe9-9f7c-4698-9690-dd8d6c9b31f4",
   "metadata": {},
   "source": [
    "Cell 11: Run Multimodal RAG Workflow\n",
    "Run the entire multimodal RAG process with a specific query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2241d8-9f55-4ef2-a49d-4170dad7d1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the multimodal RAG function with a sample query\n",
    "mm_rag(\"paragliding through the mountains\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4c3bfb-67cf-4947-b7ea-0fb581f251c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "108b599b-397d-4f1e-9030-9abebdd347dd",
   "metadata": {},
   "source": [
    "Cell 12: Close the Weaviate Client\n",
    "Ensure the Weaviate client is closed after completing the task to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81234a62-a07d-4ba7-ac84-14fccd3e9875",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the Weaviate client connection\n",
    "client.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93033b83-3360-47d7-999b-73784a13b2f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a443d0e-39bf-4542-ba14-4a6acd686a16",
   "metadata": {},
   "source": [
    "The above code demonstrates the Multimodal Retrieval-Augmented Generation (MM-RAG) workflow using Weaviate and Google Gemini Pro Vision. This process involves two main steps:\n",
    "\n",
    "Image Retrieval: The code connects to a Weaviate instance, restores prevectorized data, and allows image retrieval based on a text query. The retrieve_image() function fetches an image from the Weaviate database that matches a given query using a near_text search.\n",
    "\n",
    "Image Description Generation: After retrieving the image, the code uses Google Gemini Pro Vision (a large multimodal model) to generate a detailed description of the image. This is done via the call_LMM() function, which takes the image and a prompt, calls the model, and outputs a description.\n",
    "\n",
    "The workflow is encapsulated in the mm_rag() function, which integrates both steps: retrieving an image and generating its description based on a user query. The code concludes by closing the Weaviate client to free up resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b656217f-dcc7-4156-86de-a09e14b7d463",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bc1855-4b2a-4632-9113-85b280ef3066",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0070b015-9c68-44bd-ae02-64676236b823",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
