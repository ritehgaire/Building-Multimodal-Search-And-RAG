{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44099591-2fd9-42ae-ad56-c516d9a8d41e",
   "metadata": {},
   "source": [
    "Cell 1: Environment Setup\n",
    "The goal is to load environment variables (API keys) and configure the Google Generative AI client to access the Gemini Vision model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff0460f-0b48-4549-8487-1b76baa5dc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Load environment variables and API keys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())  # Read local .env file\n",
    "\n",
    "# Load API key for Google Generative AI\n",
    "GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Import Google Generative AI library and configure it\n",
    "import google.generativeai as genai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "# Set up the Google Generative AI client\n",
    "genai.configure(\n",
    "    api_key=GOOGLE_API_KEY,\n",
    "    transport=\"rest\",\n",
    "    client_options=ClientOptions(\n",
    "        api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "    )\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c36a5a-cdf9-4041-9727-7d3098e3ccf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4bb277d4-4529-45ad-9f4b-5cbff25467c1",
   "metadata": {},
   "source": [
    "Cell 2: Helper Functions\n",
    "Helper functions are provided to convert text to Markdown format and call the Large Multimodal Model (LMM) for image analysis.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7013c4af-701f-43dc-88fb-ef740264cf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import PIL.Image\n",
    "from IPython.display import Markdown, Image\n",
    "\n",
    "# Convert text to markdown format for better notebook display\n",
    "def to_markdown(text):\n",
    "    \"\"\"\n",
    "    Convert plain text into markdown format.\n",
    "    \n",
    "    Args:\n",
    "        text (str): The text to format.\n",
    "    \n",
    "    Returns:\n",
    "        Markdown: Formatted markdown text.\n",
    "    \"\"\"\n",
    "    text = text.replace(\"â€¢\", \"  *\")\n",
    "    return Markdown(textwrap.indent(text, \"> \", predicate=lambda _: True))\n",
    "\n",
    "# Function to call the LMM to analyze images and return a response\n",
    "def call_LMM(image_path: str, prompt: str, plain_text: bool=False) -> str:\n",
    "    \"\"\"\n",
    "    Call the LMM to analyze an image and generate a response based on a prompt.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image to be analyzed.\n",
    "        prompt (str): A text prompt for the model to process.\n",
    "        plain_text (bool): If True, returns plain text; otherwise returns Markdown.\n",
    "\n",
    "    Returns:\n",
    "        str: Model response in Markdown or plain text.\n",
    "    \"\"\"\n",
    "    img = PIL.Image.open(image_path)  # Load the image\n",
    "    model = genai.GenerativeModel(\"gemini-1.5-flash\")  # Initialize the model\n",
    "    response = model.generate_content([prompt, img], stream=True)  # Generate content\n",
    "    response.resolve()  # Resolve the content\n",
    "\n",
    "    if plain_text:\n",
    "        return response.text\n",
    "    else:\n",
    "        return to_markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3dc112-62eb-47ba-a7af-05f2ad094f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "082af734-c41b-4f42-a3d5-5221eb862e17",
   "metadata": {},
   "source": [
    "Cell 3: Extracting Structured Data from an Invoice Image\n",
    "The Large Multimodal Model (LMM) is used to analyze an invoice image and extract structured data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d78c33-7460-46b3-9fa5-6e5690f8ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the invoice image\n",
    "from IPython.display import Image\n",
    "Image(url=\"invoice.png\")\n",
    "\n",
    "# Extract structured data from the invoice (as JSON)\n",
    "call_LMM(\"invoice.png\", \n",
    "    \"\"\"Identify items on the invoice, Make sure you output \n",
    "    JSON with quantity, description, unit price, and amount.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f40bae98-1826-4d12-af2f-d1e4a37fd019",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42da1fd7-e9cb-4dd9-ab74-2c7f5ea31876",
   "metadata": {},
   "source": [
    "Cell 4: Querying Additional Information\n",
    "Ask the model follow-up questions about the invoice for specific cost estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32568968-a1ab-49b9-880d-1d33ce7000a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the model to calculate costs based on the invoice\n",
    "call_LMM(\"invoice.png\", \n",
    "    \"\"\"How much would four sets of pedal arms cost \n",
    "    and 6 hours of labor?\"\"\",\n",
    "    plain_text=True  # Return response in plain text format\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c588b-5daf-44aa-9bf3-aa8cbe4e9d5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "be82967a-13f4-4761-8b61-166847ffe315",
   "metadata": {},
   "source": [
    "Cell 5: Extracting Tables from Images\n",
    "Analyze an image of a table and extract the contents in Markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579eb671-7b6a-4ba1-b5a1-95b8e1d11c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the table image\n",
    "Image(\"prosus_table.png\")\n",
    "\n",
    "# Convert table image contents into Markdown table format\n",
    "call_LMM(\"prosus_table.png\", \n",
    "    \"Print the contents of the image as a markdown table.\"\n",
    ")\n",
    "\n",
    "# Analyze the contents of the table to find the highest revenue growth\n",
    "call_LMM(\"prosus_table.png\", \n",
    "    \"\"\"Analyze the contents of the image as a markdown table.\n",
    "    Which of the business units has the highest revenue growth?\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386036ef-a88b-436c-8225-291a8e0377bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "98dc698b-8b11-4c37-a351-f5e924a491cf",
   "metadata": {},
   "source": [
    "Cell 6: Analyzing Flow Charts\n",
    "Use the LMM to analyze a flowchart image and provide a summarized breakdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40cdc56f-be1b-4bd1-ba34-933c2eb17d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the swimlane diagram\n",
    "Image(\"swimlane-diagram-01.png\")\n",
    "\n",
    "# Provide a summarized breakdown of the flowchart as a numbered list\n",
    "call_LMM(\"swimlane-diagram-01.png\", \n",
    "    \"\"\"Provide a summarized breakdown of the flow chart in the image\n",
    "    in the format of a numbered list.\"\"\"\n",
    ")\n",
    "\n",
    "# Analyze the flow chart and generate Python code based on the logical flow\n",
    "call_LMM(\"swimlane-diagram-01.png\", \n",
    "    \"\"\"Analyze the flow chart in the image,\n",
    "    then output Python code that implements this logical flow in one function.\"\"\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c81a837-ff22-454d-bf6f-9a6f6b9316f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e4d1d414-8c75-4c05-b15d-be0657742943",
   "metadata": {},
   "source": [
    "Cell 7: Generated Python Code from Flow Chart\n",
    "The LMM generates Python code to implement the flow described in the diagram. This code can be tested, although it may require additional context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d967f843-aa3f-4bdf-b374-dec32c550dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generated Python code from the flowchart analysis\n",
    "def order_fulfillment(client, online_shop, courier_company):\n",
    "    \"\"\"\n",
    "    This function handles the order fulfillment process involving \n",
    "    a client, an online shop, and a courier company.\n",
    "    \n",
    "    Args:\n",
    "        client (object): The client who placed the order.\n",
    "        online_shop (object): The online shop processing the order.\n",
    "        courier_company (object): The courier company delivering the order.\n",
    "    \"\"\"\n",
    "    # The client places an order\n",
    "    order = client.place_order()\n",
    "\n",
    "    # The client makes a payment for the order\n",
    "    payment = client.make_payment(order)\n",
    "\n",
    "    # If payment is successful, ship the order\n",
    "    if payment.status == \"successful\":\n",
    "        online_shop.ship_order(order)\n",
    "        courier_company.transport_order(order)\n",
    "    \n",
    "    # If payment fails, cancel the order and issue a refund\n",
    "    else:\n",
    "        online_shop.cancel_order(order)\n",
    "        client.refund_order(order)\n",
    "\n",
    "    # Finally, generate an invoice for the order\n",
    "    online_shop.invoice_order(order)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a550b2-6af6-446a-ae74-a7750c1cd03f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "027825ec-b1df-4401-ad99-e7dfb09bf700",
   "metadata": {},
   "source": [
    "The above code demonstrates how to use Google Gemini Vision (Large Multimodal Model) to analyze images and generate meaningful outputs such as structured data, tables, and Python code. The workflow includes the following key tasks:\n",
    "\n",
    "Environment Setup: API keys are loaded, and the Google Generative AI client is configured to interact with the Gemini Vision model.\n",
    "\n",
    "Helper Functions: Functions are defined to convert text to markdown and to call the multimodal model for image analysis.\n",
    "\n",
    "Image Analysis: The model is used to extract structured data from an invoice, query cost estimates, and retrieve tables from images, which are output as markdown or analyzed further.\n",
    "\n",
    "Flowchart Analysis: The model analyzes flowcharts, generating a summarized breakdown and Python code that reflects the logical flow of the diagram.\n",
    "\n",
    "Generated Code: Python code generated by the model based on the flowchart is provided as an example for testing logical implementation.\n",
    "\n",
    "The notebook illustrates how industry applications can leverage multimodal AI for extracting insights from visual data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525e41bc-4b3b-455e-9283-82f106c56575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8158f9d0-0238-4758-8ba1-ee87ccbfc6b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2182263b-6cce-40b6-9057-711402fd5d78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c25bbb-5f00-4d67-8e25-a123b2a4f8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2905a2-3595-47de-a285-390c2e594852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd049855-07fc-494d-8a99-7ff933c7f50a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2452bfde-70f3-479d-bdcb-82ef52f402cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7018be18-16ee-49c9-8a2e-3437057d0edc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a10447d-0eb5-4545-be34-c1955652bfbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
