{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c183d5a8-a91c-4dbc-949c-e945f82f400b",
   "metadata": {},
   "source": [
    "Cell 1: Setup Environment Variables and API Key\n",
    "Objective: Load the environment variables and configure the Google Generative AI client with the API key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96419a89-f829-41ed-b1ea-c41a6afff661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Load environment variables and API keys\n",
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # Load .env file\n",
    "GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')  # Load API Key from .env\n",
    "\n",
    "# Set up the generative AI library\n",
    "import google.generativeai as genai\n",
    "from google.api_core.client_options import ClientOptions\n",
    "\n",
    "# Configure the API client\n",
    "genai.configure(\n",
    "        api_key=GOOGLE_API_KEY,\n",
    "        transport=\"rest\",\n",
    "        client_options=ClientOptions(\n",
    "            api_endpoint=os.getenv(\"GOOGLE_API_BASE\"),\n",
    "        ),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992fee3c-6649-4da0-b1e7-3d0bd7379caf",
   "metadata": {},
   "source": [
    "Cell 2: Helper Functions\n",
    "Objective: Define helper functions for formatting text and displaying media in Markdown format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d1333-a893-40a8-a97c-0669ec54a295",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import PIL.Image\n",
    "from IPython.display import Markdown, Image\n",
    "\n",
    "# Convert text to markdown format\n",
    "def to_markdown(text):\n",
    "    \"\"\"\n",
    "    Convert input text to Markdown for better display in notebooks.\n",
    "    \n",
    "    Args:\n",
    "        text (str): Text to be converted to Markdown.\n",
    "    \n",
    "    Returns:\n",
    "        Markdown: Markdown formatted text.\n",
    "    \"\"\"\n",
    "    text = text.replace('â€¢', '  *')\n",
    "    return Markdown(textwrap.indent(text, '> ', predicate=lambda _: True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e19b627-ccb3-47c7-8fa7-a8e51c525fde",
   "metadata": {},
   "source": [
    "Cell 3: Call the Large Multimodal Model (LMM)\n",
    "Objective: Define a function that sends an image and a prompt to the Google Generative AI model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdc28b2-b524-4b7a-a012-fc0e8265ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_LMM(image_path: str, prompt: str) -> str:\n",
    "    \"\"\"\n",
    "    Call the Large Multimodal Model (LMM) to analyze the provided image and prompt.\n",
    "\n",
    "    Args:\n",
    "        image_path (str): Path to the image file to be analyzed.\n",
    "        prompt (str): Text prompt describing the task for the model.\n",
    "\n",
    "    Returns:\n",
    "        str: Model's response formatted in Markdown.\n",
    "    \"\"\"\n",
    "    # Load the image using PIL\n",
    "    img = PIL.Image.open(image_path)\n",
    "    \n",
    "    # Call generative model using the image and prompt\n",
    "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
    "    response = model.generate_content([prompt, img], stream=True)\n",
    "    response.resolve()\n",
    "    \n",
    "    # Return the model's response in markdown format\n",
    "    return to_markdown(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e53bb0-1f3a-41f2-81b9-63c83860d95b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e799fb8e-2d21-42cf-8544-416cb1fee7a1",
   "metadata": {},
   "source": [
    "Cell 4: Analyze Image with LMM\n",
    "Objective: Use the LMM to analyze the content of an image and return a description.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8299d6f2-8609-47a1-96c9-c15a573dc639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze the SP-500 image using LMM\n",
    "Image(url=\"SP-500-Index-Historical-Chart.jpg\")  # Display the image in the notebook\n",
    "\n",
    "# Call LMM and pass the prompt to analyze the image\n",
    "call_LMM(\"SP-500-Index-Historical-Chart.jpg\", \"Explain what you see in this image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e834830-0a88-4d14-b165-dfca54d64b63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb898782-c925-46f6-ae5a-d9fa36a0aeca",
   "metadata": {},
   "source": [
    "Cell 5: Analyze a Harder Image\n",
    "Objective: Test the model with a more complex image (e.g., a diagram) to see how it handles harder cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d4d8d06-c727-40b3-adbf-5bca99495f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display and analyze a more complex image using LMM\n",
    "Image(url=\"clip.png\")\n",
    "\n",
    "# Use the LMM to describe the more complex image\n",
    "call_LMM(\"clip.png\", \"Explain what this figure is and where is this used.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c482eb0b-6324-4db5-a3a1-ab73daec9065",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a994dcfc-813a-4ae4-a6e3-f6e74fb04591",
   "metadata": {},
   "source": [
    "Cell 6: Decode a Hidden Message in an Image\n",
    "Objective: Test the model by giving it an image with a hidden message and asking it to reveal the content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb4e0f2c-e0dd-4b61-a29d-71298e8da71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and display an image with a hidden message\n",
    "Image(url=\"blankimage3.png\")\n",
    "\n",
    "# Use LMM to read and decode the hidden message in the image\n",
    "call_LMM(\"blankimage3.png\", \"Read what you see on this image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08c6625-74b6-4b24-a0a0-29d603aab895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ef389ce5-a10d-4087-8b47-63efdb455376",
   "metadata": {},
   "source": [
    "Cell 7: Visualizing How the Model \"Sees\" the Image\n",
    "Objective: Convert the image to a NumPy array and visualize the way the model interprets the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea547c3-3aaa-4a87-8dd0-806c72f7540e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio.v2 as imageio\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the image and convert it to a NumPy array\n",
    "image = imageio.imread(\"blankimage3.png\")\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Visualize the image using a threshold to highlight specific areas\n",
    "plt.imshow(np.where(image_array[:, :, 0] > 120, 0, 1), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56d31c2-6e56-48e0-b760-fccb60a98891",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f636443e-35c2-4418-80ca-c2b007e40dc0",
   "metadata": {},
   "source": [
    "Cell 8: Create Your Own Hidden Message\n",
    "Objective: Create an image with a hidden message, save it, and use the LMM to decode the message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fc0e18a-5819-4157-9ed7-517abe717ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_image_with_text(text, font_size=20, font_family='sans-serif', text_color='#73D955', background_color='#7ED957'):\n",
    "    \"\"\"\n",
    "    Create an image with hidden text inside.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to be displayed in the image.\n",
    "        font_size (int): Size of the font.\n",
    "        font_family (str): Font family to be used.\n",
    "        text_color (str): Color of the text.\n",
    "        background_color (str): Background color of the image.\n",
    "\n",
    "    Returns:\n",
    "        plt.Figure: Figure object of the created image.\n",
    "    \"\"\"\n",
    "    # Create a plot with the given text and styling\n",
    "    fig, ax = plt.subplots(figsize=(5, 5))\n",
    "    fig.patch.set_facecolor(background_color)\n",
    "    ax.text(0.5, 0.5, text, fontsize=font_size, ha='center', va='center', color=text_color, fontfamily=font_family)\n",
    "    ax.axis('off')\n",
    "    plt.tight_layout()\n",
    "    return fig\n",
    "\n",
    "# Generate an image with a hidden message\n",
    "fig = create_image_with_text(\"Hello, world!\")\n",
    "\n",
    "# Display the generated image with hidden text\n",
    "plt.show()\n",
    "\n",
    "# Save the generated image\n",
    "fig.savefig(\"extra_output_image.png\")\n",
    "\n",
    "# Use LMM to decode the hidden message\n",
    "call_LMM(\"extra_output_image.png\", \"Read what you see on this image.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b76b0d10-fbad-40d5-900e-bbc0d0cf681a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "981a6677-541e-45a1-8a61-55e82418632f",
   "metadata": {},
   "source": [
    "Cell 9: Decode the Created Hidden Message\n",
    "Objective: Convert the image with the hidden message to a NumPy array and visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34f844c-09d8-4395-8dfc-aaeb5abb94bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the image created with hidden text\n",
    "image = imageio.imread(\"extra_output_image.png\")\n",
    "\n",
    "# Convert the image to a NumPy array\n",
    "image_array = np.array(image)\n",
    "\n",
    "# Visualize the hidden text by thresholding the red channel\n",
    "plt.imshow(np.where(image_array[:, :, 0] > 120, 0, 1), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8770195d-ff6b-453b-8519-d2b05103e200",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b27dda08-351e-4cf1-8a81-7c2aaa9fe9ee",
   "metadata": {},
   "source": [
    "The above code demonstrates how to interact with a Large Multimodal Model (LMM) using the Google Generative AI API to analyze and generate content from both text and images. Here's a summary of the key components:\n",
    "\n",
    "Environment Setup: The code loads environment variables, including the Google API key, and configures the generative AI client to make API calls.\n",
    "Helper Functions: Utility functions are defined to format text and display images or markdown in the notebook.\n",
    "LMM Function: A function call_LMM is provided to load an image and a prompt, and send them to the LMM for analysis, retrieving a description or explanation from the model.\n",
    "Image Analysis: The code shows how to analyze several images using the LMM, including an SP-500 chart, a complex figure, and an image with hidden text.\n",
    "Hidden Message Creation: The notebook also allows users to create images with hidden messages and then uses the LMM to decode these messages.\n",
    "Image Processing: Finally, the notebook demonstrates how to visualize the model's interpretation of images by converting them to NumPy arrays and applying filters.\n",
    "Overall, the code showcases the use of LMM for multimodal image-text analysis and the ability to interactively generate and interpret visual data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
